{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install -q sklearn", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom six.moves import urllib\n\nimport tensorflow.compat.v2.feature_column as fc\n\nimport tensorflow as tf", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#ex. predict how likly someone is to survive the titantic, given this dataset\n\n#LOAD DATA\ndftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') #training data\ndfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') #testing data\ny_train = dftrain.pop('survived')\ny_eval = dfeval.pop('survived')", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#less testing (eval) data\ndftrain.shape #(627, 9)\ndfeval.shape #(264, 9) ", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "(264, 9)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#categorical data has to be encoded into integer values.\n#the model does not care what a category is, it just needs to know that values are different or the same. \n# sex: {famale: 0, male: 1}\n# class: {\"First\": 0, Second: 1, Third: 2}\n\nCATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\nNUMERIC_COLUMNS = ['age', 'fare']", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "feature_columns = []\nfor feature_name in CATEGORICAL_COLUMNS:\n  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) #this creates a numpy array with feature name and vocab\n    \nfor feature_name in NUMERIC_COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n    #note:ommit unique value function, can be many dif. numbers", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#print(feature_columns) - broken up:\nprint(\"Categorical:\")\n#print(dftrain['sex'].unique())\n#print(dftrain['n_siblings_spouses'].unique())\n#print(dftrain['parch'].unique())\n#print(dftrain['class'].unique())\n#print(dftrain['deck'].unique())\nprint(dftrain['embark_town'].unique())\n#print(dftrain['alone'].unique())\nprint(\"Numerical:\")\n#print(dftrain['age'].unique())\n#print(dftrain['fare'].unique())", "execution_count": 48, "outputs": [{"output_type": "stream", "text": "Categorical:\n['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\nNumerical:\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(feature_columns[0])\n#Displays: column name-- 'sex', unique features-- 'male' & 'female'", "execution_count": 49, "outputs": [{"output_type": "stream", "text": "VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#TRAINING \n#when you have large datasets, they cannot be loaded into the model all at once over RAM. Instead, we use BATCHES.\n    #for this specific model, data is going to be streamed into small BATCHES of 32. \n#The BATCHES will be fed to the model multiple times according to the number of EPOCHS. \n#An EPOCH is simply one stream of our entire dataset. The number of EPOCHS we define is the amount of times our model will see the entire dataset. \n    #we use epochs in hope that after seeing the same data multiple times the model will make a better prediction. \n    \n#incrementally add epochs to fine tune the model. adding a bunch of epochs in the beginning can result in over-fitting. ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#INPUT FUNCTION\n#input function defines how the data will be broken into epochs and batches\ndef make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n    def input_function(): #inner function, this will be returned\n        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) #create tf.data.Dataset object with data and its label\n        if shuffle:\n            ds = ds.shuffle(1000) #randomize order of data\n        ds = ds.batch(batch_size).repeat(num_epochs) #split dataset into batches of 32 and repeat process for number of epochs\n        return ds #return a batch of the dataset\n    return input_function #return a function object for use\n\ntrain_input_fn = make_input_fn(dftrain, y_train) #here we will call the inpt_function that was returned\neval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n\n#CREATING THE MODEL\nlinear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n\nlinear_est.train(train_input_fn) #train\nresult = linear_est.evaluate(eval_input_fn) #get model metrics/stats by testing on testing data\n\nclear_output() #clears concole output\nprint(result['accuracy'])", "execution_count": 74, "outputs": [{"output_type": "stream", "text": "0.75\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(result) #dataset statistics", "execution_count": 72, "outputs": [{"output_type": "stream", "text": "{'accuracy': 0.7651515, 'accuracy_baseline': 0.625, 'auc': 0.8261096, 'auc_precision_recall': 0.76914394, 'average_loss': 0.54977614, 'label/mean': 0.375, 'loss': 0.5416099, 'precision': 0.8032787, 'prediction/mean': 0.24950437, 'recall': 0.4949495, 'global_step': 200}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#TensorFLow is great for making predictions on lots of stuff at once. Not great for getting 1-piece of data.\n#Make a prediction for every single point in a dataset. \n\n#PREDICTIONS\nresult = list(linear_est.predict(eval_input_fn))\nprint(result[0]) #this is the dictionary of one prediction\nprint(result[0]['probabilities'][0]) #probability of not surviving\nprint(result[0]['probabilities'][1]) #probability of surviving\n#The probability of survival for the 1st passenger in the eval data is 6%. \n\n#Did the person survive?\nprint(y_eval.loc[0]) #0 - dead\n\n#look at the rest of that data for 1st passenger\nprint(dfeval.loc[0])\n#sex                          male\n#age                          35.0\n#n_siblings_spouses              0\n#parch                           0\n#fare                         8.05\n#class                       Third\n#deck                      unknown\n#embark_town           Southampton\n#alone                           y", "execution_count": 83, "outputs": [{"output_type": "stream", "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from /tmp/wsuser/tmp_4gtwqyd/model.ckpt-200\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n{'logits': array([-2.7469084], dtype=float32), 'logistic': array([0.06026149], dtype=float32), 'probabilities': array([0.9397385 , 0.06026149], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1], dtype=int32), 'all_classes': array([b'0', b'1'], dtype=object)}\n0.9397385\n0.060261488\n0\nsex                          male\nage                          35.0\nn_siblings_spouses              0\nparch                           0\nfare                         8.05\nclass                       Third\ndeck                      unknown\nembark_town           Southampton\nalone                           y\nName: 0, dtype: object\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}