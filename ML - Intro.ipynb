{"cells": [{"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#CREATING TENSORS\n#tensor - each tensor represents a partially defined computation that will eventually produce a value. \n#creating tensors of different datatypes:\nstring = tf.Variable(\"this is a string\", tf.string)\nnumber = tf.Variable(324, tf.int16)\nfloating = tf.Variable(3.567, tf.float64)\n\n#these tensors have a shape of 1. It is a scalar value. ", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#RANK/DEGREE OF TENSORS\n#Another word for rank is degree, simply meaning the number of dimensions involved in the tensor.\n#The tensors above are of rank 0, also known as a scalar. \nrank1_tensor = tf.Variable([\"Test\"], tf.string)\nrank2_tensor = tf.Variable([[\"test\", \"ok\"], [\"test\", \"yes\"]], tf.string)\n\n#here we have a list, and array. The list has 1 dimensions, the array has 2 dimensions. \n#determine the degree / rank: how deep is a list nested?\n\ntf.rank(rank2_tensor) #<tf.Tensor: shape=(), dtype=int32, numpy=2>", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=2>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#SHAPE OF TENSORS\n#shape of a tensor is the amount of elements that exist in each dimesnsion, or the size of the array. Sometimes it may be unknown. \nrank2_tensor.shape #TensorShape([2, 2])", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "TensorShape([2, 2])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#CHANGING SHAPE\n#you can take a rank 2 tensor with 4 elements and turn it into a rank 1 tensor with 4 elements by making a single list. \n\ntensor1 = tf.ones([1,2,3]) #tf.ones() creates a shape [1,2,3] tensor full of ones.\nprint(tensor1) #(1-interior list, 2-lists inside that list, 3-elements in the list) -> 6 elements\n#[[[1. 1. 1.]\n#  [1. 1. 1.]]]\ntensor2 = tf.reshape(tensor1, [2,3,1]) #reshape existing data to shape [2,3,1]\nprint(tensor2) #(2-interior lists, 3-lists inside those lists, 1-element in each list) -> 6 elements \n#[[[1.]\n#  [1.]\n#  [1.]]\n# [[1.]\n#  [1.]\n#  [1.]]]\ntensor3 = tf.reshape(tensor2, [3,-1])  #-1 tells the tensor to calculate the size of the dimension in that place\n                                       # this will reshape the tense to [3,2]\nprint(tensor3) #(3- lists, 2-elements in each list) -> 6 elements                       \n#[[1. 1.]\n# [1. 1.]\n# [1. 1.]]\n\n\n#the number of elements in the reshaped tensor MUST match the number in the original. ", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "tf.Tensor(\n[[[1. 1. 1.]\n  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\ntf.Tensor(\n[[[1.]\n  [1.]\n  [1.]]\n\n [[1.]\n  [1.]\n  [1.]]], shape=(2, 3, 1), dtype=float32)\ntf.Tensor(\n[[1. 1.]\n [1. 1.]\n [1. 1.]], shape=(3, 2), dtype=float32)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#TYPES OF TENSORS\n# - Variables\n# - Constant\n# - Placeholder \n# - SparseTensor\n\n#with the exception of variable, all of these tensors are immuttable, meaning their value may not change during execution. ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#EVALUATION TENSORS\n#There will be some times when we need to get a tensors value. Since tensors represent a partially complete computation we will sometimes need to run what's called a session to evaluate the tensor. \n\nwith tf.Session() as sess: #create a session using the default graph\n    tensor.eval() #tensor will be the name of your tensor", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#RESHAPING EXAMPLES\nt = tf.zeros([5,5,5,5])\nprint(t)\nt_flat = tf.reshape([625, -1],t_flat)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "tf.Tensor(\n[[[[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]]\n\n\n [[[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]]\n\n\n [[[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]]\n\n\n [[[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]]\n\n\n [[[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]\n\n  [[0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]\n   [0. 0. 0. 0. 0.]]]], shape=(5, 5, 5, 5), dtype=float32)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}